{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Project -- Online News Popularity -- Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-0a0dc557dee6>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-0a0dc557dee6>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    Source: https://archive.ics.uci.edu/ml/datasets/online+news+popularity#\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Data Set: Online News Popularity Data Set \n",
    "\n",
    "Source: https://archive.ics.uci.edu/ml/datasets/online+news+popularity#\n",
    "<br> Note: Don't use the file from this URL. Rather use the dataset attached with project as column names are changed to remove spaces.\n",
    "\n",
    "\n",
    "**Attribute Information:<br>**\n",
    "Number of Attributes: 61 including target column -- shares\n",
    "\n",
    "Attribute Information: \n",
    "0. url: URL of the article \n",
    "1. timedelta: Days between the article publication and the dataset acquisition\n",
    "2. n_tokens_title: Number of words in the title \n",
    "3. n_tokens_content: Number of words in the content \n",
    "4. n_unique_tokens: Rate of unique words in the content \n",
    "5. n_non_stop_words: Rate of non-stop words in the content \n",
    "6. n_non_stop_unique_tokens: Rate of unique non-stop words in the content \n",
    "7. num_hrefs: Number of links \n",
    "8. num_self_hrefs: Number of links to other articles published by Mashable \n",
    "9. num_imgs: Number of images \n",
    "10. num_videos: Number of videos \n",
    "11. average_token_length: Average length of the words in the content \n",
    "12. num_keywords: Number of keywords in the metadata \n",
    "13. data_channel_is_lifestyle: Is data channel 'Lifestyle'? \n",
    "14. data_channel_is_entertainment: Is data channel 'Entertainment'? \n",
    "15. data_channel_is_bus: Is data channel 'Business'? \n",
    "16. data_channel_is_socmed: Is data channel 'Social Media'? \n",
    "17. data_channel_is_tech: Is data channel 'Tech'? \n",
    "18. data_channel_is_world: Is data channel 'World'? \n",
    "19. kw_min_min: Worst keyword (min. shares) \n",
    "20. kw_max_min: Worst keyword (max. shares) \n",
    "21. kw_avg_min: Worst keyword (avg. shares) \n",
    "22. kw_min_max: Best keyword (min. shares) \n",
    "23. kw_max_max: Best keyword (max. shares) \n",
    "24. kw_avg_max: Best keyword (avg. shares) \n",
    "25. kw_min_avg: Avg. keyword (min. shares) \n",
    "26. kw_max_avg: Avg. keyword (max. shares) \n",
    "27. kw_avg_avg: Avg. keyword (avg. shares) \n",
    "28. self_reference_min_shares: Min. shares of referenced articles in Mashable \n",
    "29. self_reference_max_shares: Max. shares of referenced articles in Mashable \n",
    "30. self_reference_avg_sharess: Avg. shares of referenced articles in Mashable \n",
    "31. weekday_is_monday: Was the article published on a Monday? \n",
    "32. weekday_is_tuesday: Was the article published on a Tuesday? \n",
    "33. weekday_is_wednesday: Was the article published on a Wednesday? \n",
    "34. weekday_is_thursday: Was the article published on a Thursday? \n",
    "35. weekday_is_friday: Was the article published on a Friday? \n",
    "36. weekday_is_saturday: Was the article published on a Saturday? \n",
    "37. weekday_is_sunday: Was the article published on a Sunday? \n",
    "38. is_weekend: Was the article published on the weekend? \n",
    "39. LDA_00: Closeness to LDA topic 0 \n",
    "40. LDA_01: Closeness to LDA topic 1 \n",
    "41. LDA_02: Closeness to LDA topic 2 \n",
    "42. LDA_03: Closeness to LDA topic 3 \n",
    "43. LDA_04: Closeness to LDA topic 4 \n",
    "44. global_subjectivity: Text subjectivity \n",
    "45. global_sentiment_polarity: Text sentiment polarity \n",
    "46. global_rate_positive_words: Rate of positive words in the content \n",
    "47. global_rate_negative_words: Rate of negative words in the content \n",
    "48. rate_positive_words: Rate of positive words among non-neutral tokens \n",
    "49. rate_negative_words: Rate of negative words among non-neutral tokens \n",
    "50. avg_positive_polarity: Avg. polarity of positive words \n",
    "51. min_positive_polarity: Min. polarity of positive words \n",
    "52. max_positive_polarity: Max. polarity of positive words \n",
    "53. avg_negative_polarity: Avg. polarity of negative words \n",
    "54. min_negative_polarity: Min. polarity of negative words \n",
    "55. max_negative_polarity: Max. polarity of negative words \n",
    "56. title_subjectivity: Title subjectivity \n",
    "57. title_sentiment_polarity: Title polarity \n",
    "58. abs_title_subjectivity: Absolute subjectivity level \n",
    "59. abs_title_sentiment_polarity: Absolute polarity level \n",
    "60. shares: Number of shares (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This note book is divided in two parts\n",
    "#### Part 1 -- Explore, Understand the Data and If required perform Wrangling\n",
    "#### Part 2 -- Apply various modeling techniques and use Root Mean Square Error (RMSE) to evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "##Import the usual libraries **\n",
    "df=pd.read_csv('OnlineNewsPopularity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-18ca39286314>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffline\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_notebook_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnected\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Start of Part I --  Explore, Understand the Data and If required perform Wrangling\n",
    "#### Get the Data\n",
    "\n",
    "** Use pandas to read data as a dataframe called df.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"OnlineNewsPopularity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q1. Looking at the data above what are your first thoughts about quality of data and modeling? ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"url\",\"timedelta\"],axis = 1, inplace = True)\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of Features\n",
    "Lets find the correlation among features (very important for successfull modelling)\n",
    "\n",
    "We will plot correlation matrix using Plotly HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    go.Heatmap(\n",
    "        z= df.astype(float).corr().values,\n",
    "        x=df.columns.values,\n",
    "        y=df.columns.values,\n",
    "        colorscale='Viridis',\n",
    "        reversescale = False,\n",
    "        text = True ,\n",
    "        opacity = 1.0\n",
    "        \n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Correlation of features',\n",
    "    xaxis = dict(ticks='', nticks=36),\n",
    "    yaxis = dict(ticks='' ),\n",
    "    width = 900, height = 700,\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='labelled-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q2. What inference can be drawn from correlation heatmap? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite a few features which are not coorelated hence good for modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Of Part 2 -- Apply various modeling techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common imports for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure output is same each time code is run\n",
    "random_state = 101     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df_data,test_size=0.3):\n",
    "    X = df_data.copy()\n",
    "    X.drop(\"shares\",axis=1, inplace=True,)\n",
    "    y = df_data[\"shares\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    return X,y,X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to perform Simple Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_linear_regression(df_data,standscalar=False):\n",
    "    X,y,X_train, X_test, y_train, y_test = get_data(df_data)\n",
    "    if(standscalar):\n",
    "        print (\"Regression after applying StandardScaler\")\n",
    "        X_scaler = StandardScaler()\n",
    "        X_train = X_scaler.fit_transform(X_train)\n",
    "        X_test = X_scaler.transform(X_test)\n",
    "        \n",
    "#         y_scaler = StandardScaler()\n",
    "# #         y_train = y_scaler.fit_transform(y_train[:, None])[:, 0]\n",
    "# #         y_test = y_scaler.transform(y_test[:, None])[:, 0]\n",
    "#         y_train = y_scaler.fit_transform(y_train)\n",
    "#         y_test = y_scaler.transform(y_test)\n",
    "\n",
    "       \n",
    "     # End of If for StandardScaler  \n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train,y_train)\n",
    "    y_pred = lm.predict(X_test)\n",
    "    y_train_pred = lm.predict(X_train)\n",
    "    print (\"RMSE on Train Data is: {:.2f} :\".format( np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))) )\n",
    "    print (\"RMSE on Test Data  is: {:.2f} :\".format( np.sqrt(metrics.mean_squared_error(y_test, y_pred))) )\n",
    "    return X,y,X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Approach 1: Linear Regression ** <br>\n",
    "** Q3: What is the RMSE on Test Data for Linear Regression? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,X_train, X_test, y_train, y_test = perf_linear_regression(df)\n",
    "print (\"Median Value of Shares:\", y.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q: 4.\tChallenge Why Linear Regression should be used here ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tLinear Regression is a good starting point in case we need to predict continuous variables .  On Speed vs. Accuracy balance � it scores on Speed.  RMSE value from Linear Regression is a good indication that it is not sufficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ** Approach 2:  Use Standard Scaler to scale the data ** <br>\n",
    "StandardScaler removes the mean and scales the data to unit variance. Standardization of a dataset is a common requirement for many machine learning estimators "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling Regression with Standard Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q5: Is the RMSE better than in Approach 1 (Linear Regression) in this case? If Not Why ? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,X_train, X_test, y_train, y_test = perf_linear_regression(df,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Scalar behave badly if the individual feature do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance). StandardScaler cannot guarantee balanced feature scales in the presence of outliers. Refer to http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "** So looks like Standard Scaling is bad choice **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do analysis of target value y and see if there are outliers and we can get rid of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print (\"\\nPrinting shares count distribution data\")\n",
    "    data = y.value_counts(ascending=False)\n",
    "    print (data)\n",
    "\n",
    "# #print (y.value_counts(ascending=False))\n",
    "\n",
    "# # print (\"\\nPrinting share count\")\n",
    "# # print (y.sort_values(ascending=False) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Approach 3: Detect Outlier and remove them from data set ** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-495740b9b5b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkde\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"green\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "sns.distplot(y,kde=False,color=\"green\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [go.Bar(\n",
    "            x=y.value_counts().index.values,\n",
    "            # Use log of value_count to make graph more comprehendible \n",
    "            #y= np.log2(y.value_counts().values) \n",
    "            y= y.value_counts().values\n",
    "    )]\n",
    "\n",
    "py.iplot(data, filename='data-basic-bar',image_width=1200, image_height=1800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q6: Which data -- based on shares count should be dropped from dataset ?** <br>\n",
    "You can use just vizual cue here , we will have more formal approach in Capstone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lets get  a scatter plot of shares and respective counts\n",
    "# y_unique = y.unique()\n",
    "# sns.regplot(y_unique,y_unique,data=y,scatter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We can try multiple values, but here I will drop the data below 100,000 and then below 20,000 shares **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a generic function to filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_threshold_data(df_copy,threshold,column_name):\n",
    "    df_adjusted = df_copy[df_copy[column_name] <= threshold]\n",
    "    print (\" Original Data Count:\", len(df_copy))\n",
    "    print (\" After Adjusting Data Count:\", len(df_adjusted))\n",
    "    return df_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted = filter_threshold_data(df,100000,\"shares\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q7: What is RMSE for data filtered at 100,000 and 20,000? What inference can you draw?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,X_train, X_test, y_train, y_test = perf_linear_regression(df_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted = filter_threshold_data(df,20000,\"shares\")\n",
    "X,y,X_train, X_test, y_train, y_test = perf_linear_regression(df_adjusted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\tRMSE  for filter 100,000 � 5756.43, RMSE for filter 20,000 � 2670.63 \n",
    "Key Point is outliers skew the model hence it is important to drop them for dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Approach 4: Lets try improve the model by using DecisionTreeRegressor for regression ** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q8. Why we should use DecisionTree? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasons for using Decision Tree\n",
    "1. Decision trees implicitly perform variable screening or feature selection\n",
    "2. Nonlinear relationships between parameters do not affect tree performance\n",
    "3. It is easy to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Decision Tree Regressor\n",
    "http://scikit-learn.org/stable/modules/tree.html#tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_regression(max_depth,X_train,y_train,X_test,y_test):\n",
    "    model = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    print (\"Tree Max Depth is:\", max_depth)\n",
    "    print (\"RMSE on Train Data is: {:.2f} :\".format( np.sqrt(metrics.mean_squared_error(y_train, y_train_pred))) )\n",
    "    print (\"RMSE on Test Data is: {:.2f} :\".format( np.sqrt(metrics.mean_squared_error(y_test, y_pred))) )\n",
    "    #print (model.decision_path)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q9. For what max_depth you get least RMSE for Test Data? ** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.\tRMSE -- 2698.59  on test data is least at max_depth = 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q10. Why RMSE increases after certain max_depth? Is this sign of overfitting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very important to understand. Beyond a certain max_depth tree will start to overfit. Meaning higher no. of nodes mean more complicated model.  Sign of overfit is when training error is significantly less than test error.  In this case it starts happening from max_depth 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted = filter_threshold_data(df,20000,\"shares\")\n",
    "X,y,X_train, X_test, y_train, y_test = get_data(df_adjusted)\n",
    "max_depth_count = len(X.columns)\n",
    "\n",
    "depth_range = [1,2,5,10,15,20,25,30,35,40,max_depth_count]\n",
    "print (\"Starting Decision Tree Regression:\")\n",
    "for depth in depth_range:\n",
    "    decision_tree_regression(depth,X_train,y_train,X_test,y_test)\n",
    "    \n",
    "# End of decision tree testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Approach 5: Combining multiple techniques ** <br>\n",
    "We will use the following\n",
    "1. Use MinMaxScaler to Scale the Data\n",
    "2. Use Principal Component Analysis to restrict the no. of dimensions\n",
    "3. Use Ensemble technique AdaBoost With DecisionTreeRegressor to further improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q11. Why MinMaxScaler should be used ? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MinMaxScaler is the most famous scaling algorithm, and follows the following formula for each feature:\n",
    "xi�min(x)/(max(x)�min(x) )\n",
    "\n",
    "It essentially shrinks the range such that the range is now between 0 and 1 (or -1 to 1 if there are negative values).\n",
    "This scaler works better for cases in which the standard scaler might not work so well. If the distribution is not Gaussian or the standard deviation is very small, the min-max scaler works better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying MinMaxScaler\n",
    "\n",
    "** Q12. While applying min max scaling to normalize your features, do you apply min max scaling on the entire dataset before splitting it into training, validation and test data? -- My Favourite Question **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important to understand this point \n",
    " Split it, then scale. Imagine it this way: you have no idea what real-world data looks like, so you couldn't scale the training data to it. Your test data is the surrogate for real-world data, so you should treat it the same way.  To reiterate: Split, scale your training data, then use the scaling from your training data on the testing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adjusted = filter_threshold_data(df,20000,\"shares\")\n",
    "X,y,X_train, X_test, y_train, y_test = get_data(df_adjusted,)\n",
    "min_max_norm = MinMaxScaler()\n",
    "X_train_norm = min_max_norm.fit_transform(X_train)\n",
    "X_test_norm = min_max_norm.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA -- Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q13. What is the significance of using PCA here ? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generally do not want to feed a large number of features directly into a machine learning algorithm since some features may be irrelevant or the �intrinsic� dimensionality may be smaller than the number of features. PCA reduces dimension and make the model leaner and better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the PCA for variance upto 95 % <br>\n",
    "** Q14. How many features are there after variance is limited to 95% ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train_norm)\n",
    "X_train_normreduced =  pd.DataFrame(pca.transform(X_train_norm))\n",
    "X_train_normreduced = X_train_normreduced.loc[:,pca.explained_variance_ratio_.cumsum()<0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X_train_normreduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got 22 features for around 95 % variance. Lets use this info to do modeling further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=22)\n",
    "df_adjusted = filter_threshold_data(df,20000,\"shares\")\n",
    "X,y,X_train, X_test, y_train, y_test = get_data(df_adjusted,)\n",
    "min_max_norm = MinMaxScaler()\n",
    "X_train_norm = min_max_norm.fit_transform(X_train)\n",
    "X_test_norm = min_max_norm.transform(X_test)\n",
    "\n",
    "X_train_norm  = pca.fit_transform(X_train_norm)\n",
    "X_test_norm = pca.transform(X_test_norm)\n",
    "X_train_norm =  pd.DataFrame(X_train_norm)\n",
    "X_test_norm = pd.DataFrame(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming y . We can choose different log base also such as 2, 10 etc\n",
    "y_train_log = np.log(y_train)\n",
    "y_test_log = np.log(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q15. Why use AdaBoostRegressor ? ** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An AdaBoost regressor is a meta-estimator that begins by fitting a regressor on the original dataset and then fits additional copies of the regressor on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. As such, subsequent regressors focus more on difficult cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic function to use AdaBoostRegression for different dataset and estimator values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_boost_regression(X_train_norm,y_train_log,X_test_norm,y_test_log,n_estimators):\n",
    "    AdaDecision = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4, min_samples_leaf= 5, min_samples_split= 5),\n",
    "                                n_estimators=n_estimators)\n",
    "    AdaDecision.fit(X_train_norm, y_train_log)\n",
    "    y_pred = AdaDecision.predict(X_test_norm)\n",
    "    y_pred = pd.DataFrame(y_pred)\n",
    "    \n",
    "    y_train_pred = pd.DataFrame(AdaDecision.predict(X_train_norm) )\n",
    "    y_train_orig_pred = y_train_pred.apply(lambda x: np.exp(x))\n",
    "    \n",
    "    y_orig_pred = y_pred.apply(lambda x: np.exp(x)) # Convert Output Back from Log to Original Value\n",
    "    print (\"Estimator Count in AdaBoostRegressor:\", n_estimators)\n",
    "    print (\"RMSE on Train Data is: {:.2f} :\".format( np.sqrt(metrics.mean_squared_error(y_train, y_train_orig_pred))) )\n",
    "    print (\"RMSE on Test Data is: {:.2f} :\".format( np.sqrt(metrics.mean_squared_error(y_test, y_orig_pred))) )\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q16. For which n_estimators values do you see lowest RMSE for Test Data ? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try changing the values in n_estimators_list and see what RMSE you get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_list = [10,20,30,40,50,100,125,150]\n",
    "for n_estimator in n_estimators_list:\n",
    "    ada_boost_regression(X_train_norm,y_train_log,X_test_norm,y_test_log,n_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q17. Compare the result above with DecisionTreeRegressor approach. What inference can you draw ? ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike DecisionTreeRegressor, AdaBoostRegressor does not overfit the data for higher number of estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q18. What is your final inference ? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome! to the real world of Machine Learning. We started with Linear Regression , used scaling , removed outliers, tried  DecisionTree and AdaBoost with PCA.   We improved RMSE on test data from 11100 to around 2700 with reduction in no. of features from 58 to 22.  No mean feat!.  \n",
    "Yet something is missing here. In spite of trying various modeling, our RMSE score did not improve much after filtering <= 20,000 shares records.\n",
    " Why ? Fundamental question could be is data correct and sufficient?\n",
    "Data is off course correct, but let's explore on sufficient part. \n",
    " It's very difficult to evaluate popularity of article based on just numerical features. Reason of popularity could also be the sentiments captured by article and the timing of publishing when certain event was occurring.  And these are some of the features which seem to be missing in data. \n",
    "Remember you will not always arrive at a optimal model and that is the point when you should start looking beyond the presented dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
